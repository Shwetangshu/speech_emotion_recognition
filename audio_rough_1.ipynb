{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N8pz9RUGIRT",
        "outputId": "512eb443-d740-423c-9590-172cbb474310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        " from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x__M1aER0k0R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import librosa\n",
        "import librosa.display\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import IPython.display as ipd\n",
        "from IPython.display import Audio\n",
        "import keras\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM,BatchNormalization , GRU\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZ_8qMu-jb_Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wLMrO9Kck96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d01d23f-950f-4131-8abf-9c2bcc9cbf0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 0 B/3,626 B 0%] [Connecting to ppa.launc\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcontent.net] [Waiting for\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r                                                                                                    \r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcontent.net]\r                                                                                       \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcontent.net]\r                                                                                       \rGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [52.9 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,755 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,370 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,077 kB]\n",
            "Get:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,035 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [28.3 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [44.2 kB]\n",
            "Fetched 6,747 kB in 2s (3,818 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libsndfile1 is already the newest version (1.0.31-2ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y libsndfile1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoU8kkk9dhFl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5918ae20-9862-4de1-b799-739f1c07a01c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_24', 'Actor_14', 'Actor_19', 'Actor_17', 'Actor_16', 'Actor_18', 'Actor_20', 'Actor_22', 'Actor_21', 'Actor_23', 'Actor_15', 'Actor_13', 'Actor_06', 'Actor_09', 'Actor_08', 'Actor_10', 'Actor_11', 'Actor_05', 'Actor_04', 'Actor_12', 'Actor_07', 'Actor_03', 'Actor_01', 'Actor_02']\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "ravdess = '/content/drive/My Drive/DATASET_1'\n",
        "files_lis_dir = os.listdir(ravdess)\n",
        "print(files_lis_dir)\n",
        "print(\"Done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BafOWUDv9-L5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "427c41a2-5a81-45c9-8437-dcfeae9a6aa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell executed\n",
            "size of file path :  1440 and file emotion:  1440\n"
          ]
        }
      ],
      "source": [
        "#for ravdess dataset, storing path and emotion\n",
        "file_path = []\n",
        "file_emotion = []\n",
        "for f in files_lis_dir:\n",
        "  actor = os.listdir(os.path.join(ravdess, f))\n",
        "  for a in actor: #for all audio files\n",
        "    audio = a.split('.')[0].split('-')\n",
        "    file_emotion.append(int(audio[2]))\n",
        "    file_path.append(ravdess + f + '/' + a)\n",
        "print(\"Cell executed\")\n",
        "print(\"size of file path : \", len(file_path), \"and file emotion: \", len(file_emotion))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oITobi--GHdx"
      },
      "outputs": [],
      "source": [
        "# for i in range(24):\n",
        "#   print(actor[i])\n",
        "# for i in range( 10):\n",
        "#   print(store_emotion[i])\n",
        "\n",
        "# print(\"File path : \", store_path[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLW24qmk-KVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff1372c8-4b2c-4735-cb6c-07d9f3f80f6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cell exec\n"
          ]
        }
      ],
      "source": [
        "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
        "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
        "ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
        "ravdess_df.Emotions.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust',8:'surprise'},inplace=True)\n",
        "print(\"cell exec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4me_8C5aPMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a3665c-9a28-4996-b329-fa3a7a29bcc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Emotions                                               Path\n",
            "0      sad  /content/drive/My Drive/DATASET_1Actor_24/03-0...\n",
            "1    angry  /content/drive/My Drive/DATASET_1Actor_24/03-0...\n",
            "2    happy  /content/drive/My Drive/DATASET_1Actor_24/03-0...\n",
            "3     fear  /content/drive/My Drive/DATASET_1Actor_24/03-0...\n",
            "4     fear  /content/drive/My Drive/DATASET_1Actor_24/03-0...\n",
            "---------------\n",
            "      Emotions                                               Path\n",
            "1435   disgust  /content/drive/My Drive/DATASET_1Actor_02/03-0...\n",
            "1436  surprise  /content/drive/My Drive/DATASET_1Actor_02/03-0...\n",
            "1437  surprise  /content/drive/My Drive/DATASET_1Actor_02/03-0...\n",
            "1438  surprise  /content/drive/My Drive/DATASET_1Actor_02/03-0...\n",
            "1439   disgust  /content/drive/My Drive/DATASET_1Actor_02/03-0...\n",
            "----------\n",
            "Emotions\n",
            "neutral     288\n",
            "sad         192\n",
            "angry       192\n",
            "happy       192\n",
            "fear        192\n",
            "disgust     192\n",
            "surprise    192\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(ravdess_df.head())\n",
        "print(\"---------------\")\n",
        "print(ravdess_df.tail())\n",
        "print(\"----------\")\n",
        "print(ravdess_df['Emotions'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7uRQ7wTaUKv"
      },
      "outputs": [],
      "source": [
        "#second dataset\n",
        "crema ='/content/drive/My Drive/DATASET_2_CREMA'\n",
        "# files = os.listdir(crema)\n",
        "# num_files = len(files)\n",
        "# print(num_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSaKL785sTWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14a0ff3-47fe-4679-9109-575ae24357ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotions\n",
            "fear       1188\n",
            "disgust    1187\n",
            "sad        1187\n",
            "angry      1187\n",
            "happy      1186\n",
            "neutral    1015\n",
            "Name: count, dtype: int64\n",
            "Cell executed\n",
            "size of file path :  6950 and file emotion:  6950\n"
          ]
        }
      ],
      "source": [
        "crema_dir_list = os.listdir(crema)\n",
        "file_path = []\n",
        "file_emotion = []\n",
        "\n",
        "for i in crema_dir_list:\n",
        "    # storing file paths\n",
        "    file_path.append(crema + i)\n",
        "    # storing file emotions\n",
        "    part=i.split('_')\n",
        "    if part[2] == 'SAD':\n",
        "        file_emotion.append('sad')\n",
        "    elif part[2] == 'ANG':\n",
        "        file_emotion.append('angry')\n",
        "    elif part[2] == 'DIS':\n",
        "        file_emotion.append('disgust')\n",
        "    elif part[2] == 'FEA':\n",
        "        file_emotion.append('fear')\n",
        "    elif part[2] == 'HAP':\n",
        "        file_emotion.append('happy')\n",
        "    elif part[2] == 'NEU':\n",
        "        file_emotion.append('neutral')\n",
        "    else:\n",
        "        file_emotion.append('Unknown')\n",
        "\n",
        "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
        "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
        "crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
        "\n",
        "crema_df.head()\n",
        "print(crema_df.Emotions.value_counts())\n",
        "print(\"Cell executed\")\n",
        "print(\"size of file path : \", len(file_path), \"and file emotion: \", len(file_emotion))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Zxn2aIrxgSq"
      },
      "outputs": [],
      "source": [
        "#third dataset\n",
        "savee ='/content/drive/My Drive/DATASET_3_SAVEE/ALL'\n",
        "savee_dl = os.listdir(savee)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQIygVN30xC9"
      },
      "outputs": [],
      "source": [
        "# files = os.listdir(savee)\n",
        "# for entry in files:\n",
        "\n",
        "#     entry_path = os.path.join(savee, entry)\n",
        "#     if os.path.isdir(entry_path):\n",
        "#         subfiles = os.listdir(entry_path)\n",
        "#         print(f\"Number of files in '{entry}': {len(subfiles)}\")\n",
        "# print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCn1JZg31WN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da24dede-ee17-4f7b-838e-d5531ea9784a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotions\n",
            "neutral     120\n",
            "angry        60\n",
            "fear         60\n",
            "happy        60\n",
            "disgust      60\n",
            "sad          60\n",
            "surprise     60\n",
            "Name: count, dtype: int64\n",
            "Cell executed\n",
            "size of file path :  480 and file emotion:  480\n"
          ]
        }
      ],
      "source": [
        "file_path = []\n",
        "file_emotion = []\n",
        "for i in savee_dl:\n",
        "    file_path.append(savee + i)\n",
        "    part = i.split('_')[1]\n",
        "    ele = part[:-6]\n",
        "    if ele=='a':\n",
        "        file_emotion.append('angry')\n",
        "    elif ele=='d':\n",
        "        file_emotion.append('disgust')\n",
        "    elif ele=='f':\n",
        "        file_emotion.append('fear')\n",
        "    elif ele=='h':\n",
        "        file_emotion.append('happy')\n",
        "    elif ele=='n':\n",
        "        file_emotion.append('neutral')\n",
        "    elif ele=='sa':\n",
        "        file_emotion.append('sad')\n",
        "    else:\n",
        "        file_emotion.append('surprise')\n",
        "\n",
        "\n",
        "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
        "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
        "savee_df = pd.concat([emotion_df, path_df], axis=1)\n",
        "savee_df.head()\n",
        "print(savee_df['Emotions'].value_counts())\n",
        "print(\"Cell executed\")\n",
        "print(\"size of file path : \", len(file_path), \"and file emotion: \", len(file_emotion))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q3qsDLyDg3L"
      },
      "outputs": [],
      "source": [
        "#fourth dataset\n",
        "tess = '/content/drive/My Drive/tess_moved'\n",
        "tess_dl = os.listdir(tess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJG-wz4cEjP4"
      },
      "outputs": [],
      "source": [
        "file_emotion = []\n",
        "file_path = []\n",
        "for dir in tess_dl:\n",
        "    files = os.listdir(os.path.join(tess, dir))\n",
        "    for file in files:\n",
        "        part = file.split('.')[0]\n",
        "        part = part.split('_')[2]\n",
        "        if part == 'ps':\n",
        "            file_emotion.append('surprise')\n",
        "        else:\n",
        "            file_emotion.append(part)\n",
        "        full_path = os.path.join(tess, dir, file)\n",
        "        file_path.append(full_path)\n",
        "\n",
        "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
        "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
        "tess_df = pd.concat([emotion_df, path_df], axis=1)\n",
        "print(tess_df.head())\n",
        "print(tess_df.Emotions.value_counts())\n",
        "print(\"Cell executed\")\n",
        "print(\"size of file path : \", len(file_path), \"and file emotion: \", len(file_emotion))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94mVj0OjFQ0a"
      },
      "outputs": [],
      "source": [
        "#combining all\n",
        "df = pd.concat([ravdess_df, crema_df, tess_df, savee_df], axis = 0)\n",
        "df.to_csv(\"df.csv\",index=False)\n",
        "print(df.head())\n",
        "print(df['Emotions'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T1peYf6hCfK"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"/content/drive/My Drive/df.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10XUrI-ejsMA"
      },
      "outputs": [],
      "source": [
        "# #plotting one sample\n",
        "\n",
        "# plt.figure(figsize = (10, 5))\n",
        "# spect = librosa.feature.melspectrogram(y = data, sr= sr, n_mels = 128, fmax = 10000)\n",
        "# log_spect = librosa.power_to_db(spect) #now in db, log le liya\n",
        "# librosa.display.specshow(log_spect, y_axis = 'mel', sr = sr, x_axis = 'time')\n",
        "# plt.title('Mel Spectrogram ')\n",
        "# plt.colorbar(format='%+2.0f dB')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E02hUeY1m3Sb"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/My Drive/df.csv'\n",
        "df1 = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "logTU9w2cKFO"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKVdcJllkm1c"
      },
      "source": [
        "#features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7U0EMj-cLag"
      },
      "outputs": [],
      "source": [
        "def oneliner_ae(signal, frame_size, hop_length):\n",
        "  return np.array([max(signal[i:i+frame_size]) for i in range(0,len(signal), hop_length)])\n",
        "\n",
        "def rms_energy(signal, frame_size, hop_length):\n",
        "  return np.array(librosa.feature.rms(y = signal, frame_length = frame_size, hop_length = hop_length))[0] #0th row to be accessed\n",
        "\n",
        "def zcr(signal, frame_size, hop_length):\n",
        "  return np.array(librosa.feature.zero_crossing_rate(y = signal, frame_length = frame_size, hop_length = hop_length))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRKLjHcMmgPY"
      },
      "outputs": [],
      "source": [
        "def calc_split_freq_bin(spectrogram, split_freq, sr):\n",
        "  freq_range = sr/2\n",
        "  freq_delta_per_bin = freq_range / spectrogram.shape[0] #.[0] for time accessing\n",
        "  split_freq_bin = np.floor(freq_range/freq_delta_per_bin)\n",
        "  return int(split_freq_bin)\n",
        "\n",
        "def band_energy_ratio(spectrogram, split_freq, sr):\n",
        "  split_freq_bin = calc_split_freq_bin(spectrogram, split_freq, sr)\n",
        "\n",
        "  ber = []\n",
        "  power_spec = np.abs(spectrogram)**2\n",
        "  power_spec = power_spec.T\n",
        "\n",
        "  for i in power_spec:\n",
        "    power_low_freq = np.sum(i[:split_freq_bin])\n",
        "    power_high_freq = np.sum(i[split_freq_bin:])\n",
        "    ber_current = power_low_freq / power_high_freq\n",
        "    ber.append(ber_current)\n",
        "  return np.array(ber)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYJCpNr3xn6u"
      },
      "outputs": [],
      "source": [
        "def spectral_centroid(signal, sr, frame_size, hop_length):\n",
        "  return librosa.fratures.spectral_centroid(signal, sr, n_fft = frame_size, hop_length = hop_length)[0]\n",
        "\n",
        "def bandwidth(signal, sr, frame_size, hop_length):\n",
        "  return librosa.fratures.bandwidth(signal, sr, n_fft = frame_size, hop_length = hop_length)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCOdxfjr0aOW"
      },
      "outputs": [],
      "source": [
        "def mfcc(signal, coef, sr):\n",
        "  mfcc1 = librosa.feature.mfcc(signal, n_mfcc = coef, sr = sr)\n",
        "  mfcc_delta_1 = librosa.feature.delta(mfcc1)\n",
        "  mfcc_delta_2 = librosa.feature.delta(mfcc1, order = 2)\n",
        "  final = np.concatenate((mfcc1, mfcc_delta_1, mfcc_delta_2))\n",
        "  return final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1WoZKtT2Zc8"
      },
      "outputs": [],
      "source": [
        "debussy_aud = '/content/debussy.wav'\n",
        "duke_aud = '/content/duke.wav'\n",
        "redhot_aud = '/content/redhot.wav'\n",
        "violin_c_aud = '/content/violin_c.wav'\n",
        "piano_aud = '/content/piano.wav'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbG26JGG5XNG"
      },
      "outputs": [],
      "source": [
        "debussy , sr = librosa.load(debussy_aud)\n",
        "duke , _ = librosa.load(duke_aud)\n",
        "debussy , _ = librosa.load(redhot_aud)\n",
        "violin_c, _  = librosa.load(violin_c_aud)\n",
        "piano, _  = librosa.load(piano_aud)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n5XipXs_aHG"
      },
      "outputs": [],
      "source": [
        "def plot_mag_spec(signal, sr, f_ratio): #fratio for the fraction\n",
        "  ft = np.fft.fft(signal)\n",
        "  mag_spec = np.abs(ft)\n",
        "  plt.figure(figsize = (20, 6))\n",
        "  freq = np.linspace(0, sr, len(mag_spec))\n",
        "  freq_bins = int(len(freq)*f_ratio)\n",
        "  plt.plot(freq[:freq_bins], mag_spec[:freq_bins])\n",
        "  plt.title(\"magnitude spectrum\")\n",
        "  plt.xlabel(\"Freq (Hz)\")\n",
        "  plt.ylabel(\"Magnitude\")\n",
        "  plt.show()\n",
        "\n",
        "def vis_spectrogram(Y, sr, hop_length, y_axis = \"linear\"):\n",
        "  plt.figure(figsize = (20, 8))\n",
        "  librosa.display.specshow(\n",
        "                         Y,\n",
        "                        sr = sr,\n",
        "                         hop_length = hop_length,\n",
        "                         x_axis = \"time\",\n",
        "                         y_axis = y_axis\n",
        "\n",
        "  )\n",
        "  plt.colorbar(format = \"%+2.f\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XskEGz8q8vZS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keY76Ilm9QKd"
      },
      "outputs": [],
      "source": [
        "# plot_mag_spec(piano, sr, 1)\n",
        "#spectrograms\n",
        "#s_scale = librosa.stft(signal, n_fft, hop_size )\n",
        "#y_scale = np.abs(s_scale) ** 2 # complex -> real mag\n",
        "s_scale = librosa.stft(piano, n_fft = 1024, hop_length = 512)\n",
        "y_scale = np.abs(s_scale) ** 2\n",
        "vis_spectrogram(y_scale, sr, 512)\n",
        "y_log_scale = librosa.power_to_db(y_scale)\n",
        "#so now, log amplitude spectrogram if we pass this\n",
        "vis_spectrogram(y_log_scale, sr, 512)\n",
        "#now log amp log freq, so log spectrrogram, as we perceivee aisa dikhega\n",
        "vis_spectrogram(y_log_scale, sr, 512, y_axis = \"log\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mel spectrograms\n",
        "filter_banks = librosa.filters.mel(n_fft = 2048, sr = 22050, n_mels =10)\n",
        "filter_banks.shape\n",
        "mel_spectrogram = librosa.feature.melspectrogram(y = piano, sr = sr, n_fft =2048, hop_length = 512, n_mels = 10)\n",
        "# mel_spectrogram.shape\n",
        "log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)"
      ],
      "metadata": {
        "id": "J2d20h2vyk5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (20, 8))\n",
        "librosa.display.specshow(\n",
        "    log_mel_spectrogram,\n",
        "    x_axis = \"time\",\n",
        "    y_axis = \"mel\",\n",
        "    sr = sr\n",
        ")\n",
        "plt.colorbar(format = \"%+2.f\")\n",
        "plt.show()\n",
        "# can see 10 mels as n_mels is 10 here"
      ],
      "metadata": {
        "id": "ND5teHC0yk1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "debussy_spec = librosa.stft(debussy, n_fft = 2048, hop_length = 512)\n",
        "debussy_ber  = band_energy_ratio(debussy_spec, 2000, 22050)\n",
        "# debussy_ber.shape"
      ],
      "metadata": {
        "id": "WOmRGrXgyktz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize spec:\n",
        "frames = range(len(debussy_ber))\n",
        "t = librosa.frames_to_time(frames)\n",
        "plt.figure(figsize = (20, 8))\n",
        "plt.plot(t, debussy_ber, color= 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WP067WeBykjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uuM90kfM-phY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}